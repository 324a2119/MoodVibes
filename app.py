import streamlit as st
import spotipy
from spotipy.oauth2 import SpotifyClientCredentials
import tempfile
import os
from dotenv import load_dotenv
from transformers import pipeline
import librosa
from streamlit_webrtc import webrtc_streamer, WebRtcMode, AudioProcessorBase
import numpy as np
import io
from scipy.io.wavfile import write as write_wav

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# æ„Ÿæƒ…åˆ†æãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åˆ©ç”¨ã—ã¦é«˜é€ŸåŒ–ï¼‰
@st.cache_resource
def load_emotion_model():
    # åˆå›å®Ÿè¡Œæ™‚ã€ãƒ¢ãƒ‡ãƒ«ï¼ˆç´„350MBï¼‰ãŒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™
    return pipeline("audio-classification", model="superb/hubert-base-superb-er")

# ==========================
# Spotifyèªè¨¼
# ==========================
CLIENT_ID = os.getenv("SPOTIPY_CLIENT_ID")
CLIENT_SECRET = os.getenv("SPOTIPY_CLIENT_SECRET")

if not CLIENT_ID or not CLIENT_SECRET:
    st.error("Spotifyã®èªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç’°å¢ƒå¤‰æ•°ï¼ˆ.envãƒ•ã‚¡ã‚¤ãƒ«ãªã©ï¼‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(
    client_id=CLIENT_ID,
    client_secret=CLIENT_SECRET
))

# ==========================
# Streamlit UI
# ==========================
st.title("ğŸµ éŸ³å£°ã‹ã‚‰æ„Ÿæƒ…ã‚’èª­ã¿å–ã£ã¦Spotifyãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆæ¤œç´¢")
st.write("ãƒã‚¤ã‚¯ã§è©±ã™ã‹ã€éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦æ„Ÿæƒ…ã‚’æ¤œå‡ºã—ã¾ã™ã€‚")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã¨å‡¦ç†çŠ¶æ…‹ã‚’ç®¡ç†
if "audio_path" not in st.session_state:
    st.session_state.audio_path = None
if "processing_done" not in st.session_state:
    st.session_state.processing_done = True

input_mode = st.radio("éŸ³å£°å…¥åŠ›æ–¹æ³•ã‚’é¸ã‚“ã§ãã ã•ã„ï¼š", ["ğŸ™ï¸ ãƒã‚¤ã‚¯ã§è©±ã™", "ğŸ“ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"])

audio_path = None

# ==========================
# ğŸ¤ ãƒã‚¤ã‚¯éŒ²éŸ³ãƒ¢ãƒ¼ãƒ‰ (streamlit-webrtc)
# ==========================
class AudioProcessor(AudioProcessorBase):
    def __init__(self):
        self.audio_frames = []

    def recv(self, frame):
        # éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è“„ç©
        self.audio_frames.append(frame.to_ndarray())
        return frame

if input_mode == "ğŸ™ï¸ ãƒã‚¤ã‚¯ã§è©±ã™":
    st.info("ğŸ¤ é–‹å§‹ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦æ„Ÿæƒ…ã‚’è©±ã—ã¦ãã ã•ã„ã€‚è©±ã—çµ‚ã‚ã£ãŸã‚‰åœæ­¢ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
    
    webrtc_ctx = webrtc_streamer(
        key="speech-to-text",
        mode=WebRtcMode.SENDONLY,
        audio_processor_factory=AudioProcessor,
        media_stream_constraints={"video": False, "audio": True},
    )

    if not webrtc_ctx.state.playing and webrtc_ctx.audio_processor and not st.session_state.processing_done:
        st.info("éŒ²éŸ³ã‚’å‡¦ç†ã—ã¦ã„ã¾ã™...")
        
        # è“„ç©ã—ãŸéŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’çµåˆ
        audio_frames = webrtc_ctx.audio_processor.audio_frames
        if audio_frames:
            sound_chunk = np.concatenate(audio_frames, axis=0)
            sample_rate = 48000 # webrtcã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ

            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                # numpyé…åˆ—ã‚’wavå½¢å¼ã®ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
                buffer = io.BytesIO()
                write_wav(buffer, rate=sample_rate, data=sound_chunk)
                tmp_file.write(buffer.read())
                audio_path = tmp_file.name
                st.session_state.audio_path = audio_path
        
        st.session_state.processing_done = True
        st.rerun() # ãƒšãƒ¼ã‚¸ã‚’å†å®Ÿè¡Œã—ã¦çµæœã‚’è¡¨ç¤º

    if webrtc_ctx.state.playing:
        # éŒ²éŸ³é–‹å§‹æ™‚ã«çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
        st.session_state.processing_done = False
        st.session_state.audio_path = None

# ==========================
# ğŸ“ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰éŸ³å£°ãƒ¢ãƒ¼ãƒ‰
# ==========================
elif input_mode == "ğŸ“ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
    st.session_state.processing_done = True # ãƒ¢ãƒ¼ãƒ‰åˆ‡æ›¿æ™‚ã«ãƒªã‚»ãƒƒãƒˆ
    st.session_state.audio_path = None

    uploaded_file = st.file_uploader("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["wav", "mp3", "m4a"])
    if uploaded_file:
        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_file.name)[1]) as tmp_file:
            tmp_file.write(uploaded_file.getbuffer())
            audio_path = tmp_file.name
            st.session_state.audio_path = audio_path
        st.rerun()

# ==========================
# æ„Ÿæƒ…åˆ†æ ï¼† Spotifyæ¤œç´¢
# ==========================
if st.session_state.audio_path:
    st.success("âœ… éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å—ã‘ä»˜ã‘ã¾ã—ãŸã€‚åˆ†æã‚’é–‹å§‹ã—ã¾ã™ã€‚")
    current_audio_path = st.session_state.audio_path
    
    try:
        # ãƒ¢ãƒ‡ãƒ«ãŒæœŸå¾…ã™ã‚‹16kHzã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦èª­ã¿è¾¼ã¿
        speech, sr = librosa.load(current_audio_path, sr=16000)

        # æ„Ÿæƒ…ã‚’åˆ†æ
        emotion_classifier = load_emotion_model()
        results = emotion_classifier(speech)
        top_emotion = results[0]['label']
        
        st.success(f"æ„Ÿæƒ…åˆ†æã®çµæœ: **{top_emotion}**")

        # è‹±èªãƒ©ãƒ™ãƒ«ã‚’æ—¥æœ¬èªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«ãƒãƒƒãƒ”ãƒ³ã‚°
        emotion_map = {
            "happy": "æ¥½ã—ã„",
            "sad": "æ‚²ã—ã„",
            "angry": "æ¿€ã—ã„",
            "neutral": "è½ã¡ç€ã",
        }
        keyword = emotion_map.get(top_emotion)

        if not keyword:
            st.info(f"æ„Ÿæƒ…ã€Œ{top_emotion}ã€ã«å¯¾å¿œã™ã‚‹æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            st.write(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€Œ{keyword}ã€ã§ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆã‚’æ¤œç´¢ã—ã¾ã™ã€‚")
            
            st.subheader(f"ğŸ§ ã€Œ{keyword}ã€ã«é–¢é€£ã™ã‚‹ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆ")
            search_results = sp.search(q=f"{keyword} ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆ", type="playlist", limit=5, market="JP")
            playlists = search_results["playlists"]["items"]

            if not playlists:
                st.write("è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            else:
                for playlist in playlists:
                    if not playlist:
                        continue
                    playlist_name = playlist["name"]
                    playlist_owner = playlist["owner"].get("display_name", "ä¸æ˜")
                    playlist_url = playlist["external_urls"]["spotify"]
                    playlist_image = playlist["images"][0]["url"] if playlist["images"] else None
                    playlist_id = playlist["id"]

                    with st.expander(f"ğŸµ {playlist_name}  ({playlist_owner})"):
                        if playlist_image:
                            st.image(playlist_image, width=300)
                        st.markdown(f"[Spotifyã§é–‹ã]({playlist_url})")
                        tracks = sp.playlist_tracks(playlist_id)
                        st.write("ğŸ¶ æ›²ä¸€è¦§ï¼š")
                        for t in tracks["items"]:
                            track = t["track"]
                            if track:
                                name = track["name"]
                                artist = track["artists"][0]["name"]
                                st.write(f"- {name} / {artist}")
    except Exception as e:
        st.error(f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    finally:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚’ãƒªã‚»ãƒƒãƒˆ
        if os.path.exists(current_audio_path):
            os.remove(current_audio_path)
        st.session_state.audio_path = None
        st.session_state.processing_done = True