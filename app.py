import streamlit as st
import spotipy
from spotipy.oauth2 import SpotifyClientCredentials
import speech_recognition as sr
import tempfile
import os
from streamlit_webrtc import webrtc_streamer, WebRtcMode, AudioProcessorBase
from openai import OpenAI

# ==========================
# OpenAI Whisperï¼ˆAPIã‚­ãƒ¼ã‚’ãƒ™ã‚¿æ›¸ãï¼‰
# ==========================
client = OpenAI(api_key="YOUR_OPENAI_API_KEY")

# ==========================
# Spotifyèªè¨¼
# ==========================
CLIENT_ID = "ff259b9ec7f3420381662c278fed342f"
CLIENT_SECRET = "a35403dc7fb64531ba6a98c5794fcef8"

sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(
    client_id=CLIENT_ID,
    client_secret=CLIENT_SECRET
))

# ==========================
# Streamlit UI
# ==========================
st.title("ğŸµ éŸ³å£°ã‹ã‚‰æ„Ÿæƒ…ã‚’èª­ã¿å–ã£ã¦Spotifyãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆæ¤œç´¢")
st.write("ãƒã‚¤ã‚¯ã§è©±ã™ã‹ã€éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦æ„Ÿæƒ…ã‚’æ¤œå‡ºã—ã¾ã™ã€‚")

input_mode = st.radio("éŸ³å£°å…¥åŠ›æ–¹æ³•ã‚’é¸ã‚“ã§ãã ã•ã„ï¼š",
                      ["ğŸ™ï¸ ãƒã‚¤ã‚¯ã§è©±ã™", "ğŸ“ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"])

audio_path = None

# ==========================
# ãƒã‚¤ã‚¯éŒ²éŸ³ãƒ¢ãƒ¼ãƒ‰
# ==========================
class AudioProcessor(AudioProcessorBase):
    def __init__(self):
        self.audio_frames = b""

    def recv_audio(self, frame):
        self.audio_frames += frame.to_ndarray().tobytes()
        return frame


if input_mode == "ğŸ™ï¸ ãƒã‚¤ã‚¯ã§è©±ã™":
    st.info("ğŸ¤ æ„Ÿæƒ…ã‚’å«ã‚€è¨€è‘‰ã‚’è©±ã—ã¦ãã ã•ã„ã€‚éŒ²éŸ³ãŒçµ‚ã‚ã£ãŸã‚‰åœæ­¢ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")

    webrtc_ctx = webrtc_streamer(
        key="speech-capture",
        mode=WebRtcMode.SENDRECV,
        audio_receiver_size=1024,
        media_stream_constraints={"audio": True, "video": False},
        async_processing=True,
        audio_processor_factory=AudioProcessor,
    )

    if webrtc_ctx and webrtc_ctx.state.playing:
        st.info("éŒ²éŸ³ä¸­ã§ã™â€¦åœæ­¢ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨å‡¦ç†ãŒå§‹ã¾ã‚Šã¾ã™ã€‚")

    if webrtc_ctx and not webrtc_ctx.state.playing:
        if hasattr(webrtc_ctx, "audio_processor") and webrtc_ctx.audio_processor:
            audio_data = webrtc_ctx.audio_processor.audio_frames
            if audio_data:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_wav:
                    tmp_wav.write(audio_data)
                    audio_path = tmp_wav.name
                    st.success("ğŸ™ï¸ éŒ²éŸ³å®Œäº†ï¼")

# ==========================
# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ¢ãƒ¼ãƒ‰
# ==========================
elif input_mode == "ğŸ“ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
    uploaded_file = st.file_uploader("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ (wav/mp3)", type=["wav", "mp3"])
    if uploaded_file is not None:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            tmp_file.write(uploaded_file.read())
            audio_path = tmp_file.name
            st.success("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å—ã‘å–ã‚Šã¾ã—ãŸ")

# ==========================
# Whisper éŸ³å£° â†’ ãƒ†ã‚­ã‚¹ãƒˆ
# ==========================
if audio_path:
    st.info("ğŸ§ Whisperã§éŸ³å£°ã‚’è§£æã—ã¦ã„ã¾ã™â€¦")

    try:
        with open(audio_path, "rb") as f:
            transcript = client.audio.transcriptions.create(
                model="gpt-4o-mini-transcribe",
                file=f
            )
        text = transcript.text
    except Exception as e:
        st.error(f"éŸ³å£°èªè­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        st.stop()

    st.success("ğŸ—£ï¸ éŸ³å£°èªè­˜çµæœ:")
    st.write(text)

    # ==========================
    # æ„Ÿæƒ…å˜èªæŠ½å‡º
    # ==========================
    emotion_words = ["æ¥½ã—ã„", "æ‚²ã—ã„", "ãƒ¯ã‚¯ãƒ¯ã‚¯", "è½ã¡ç€ã", "å…ƒæ°—", "åˆ‡ãªã„"]
    detected = [w for w in emotion_words if w in text]

    if not detected:
        st.info("æ„Ÿæƒ…ã‚’è¡¨ã™å˜èªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        st.write("æŠ½å‡ºã•ã‚ŒãŸæ„Ÿæƒ…å˜èª:", ", ".join(detected))

        # ==========================
        # Spotifyæ¤œç´¢ï¼ˆé‚¦æ¥½ã«å¯„ã›ã‚‹ï¼‰
        # ==========================
        for keyword in detected:
            st.subheader(f"ğŸ§ ã€Œ{keyword}ã€ã«é–¢é€£ã™ã‚‹ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆ")

            results = sp.search(q=f"{keyword} ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆ", type="playlist", limit=5, market="JP")
            playlists = results['playlists']['items']

            if not playlists:
                st.write("è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                continue

            for playlist in playlists:
                name = playlist["name"]
                owner = playlist["owner"].get("display_name", "ä¸æ˜")
                image = playlist["images"][0]["url"] if playlist["images"] else None
                url = playlist["external_urls"]["spotify"]
                playlist_id = playlist["id"]

                with st.expander(f"ğŸµ {name}  ({owner})"):
                    if image:
                        st.image(image, width=300)
                    st.markdown(f"[Spotifyã§é–‹ã]({url})")

                    # æ›²ä¸€è¦§
                    tracks = sp.playlist_tracks(playlist_id)
                    st.write("ğŸ¶ æ›²ä¸€è¦§ï¼š")
                    for t in tracks["items"]:
                        track = t["track"]
                        if track:
                            tname = track["name"]
                            aname = track["artists"][0]["name"]
                            st.write(f"- {tname} / {aname}")

    os.remove(audio_path)
